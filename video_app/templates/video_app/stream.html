{% extends "video_app/main.html" %}
{% load static %}

{% block title %}Live Gesture Recognition - Hand Gesture Communication App{% endblock %}

{% block styles %}
<style>
    .stream-hero {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        padding: 100px 0 60px;
        text-align: center;
        position: relative;
        overflow: hidden;
    }
    
    .stream-hero::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="waves" width="100" height="100" patternUnits="userSpaceOnUse"><path d="M0,50 Q25,0 50,50 T100,50" stroke="white" stroke-width="1" fill="none" opacity="0.1"/></pattern></defs><rect width="100" height="100" fill="url(%23waves)"/></svg>');
        opacity: 0.3;
    }
    
    .stream-hero-content {
        position: relative;
        z-index: 2;
    }
    
    .stream-title {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 1rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .stream-subtitle {
        font-size: 1.2rem;
        opacity: 0.9;
        margin-bottom: 2rem;
    }
    
    .stream-container {
        background: white;
        border-radius: 20px;
        padding: 2rem;
        margin: 2rem 0;
        box-shadow: 0 20px 40px rgba(0,0,0,0.1);
    }
    
    .video-section {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 2rem;
        margin-bottom: 2rem;
    }
    
    .video-container {
        position: relative;
        border-radius: 15px;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        background: #1e293b;
    }
    
    .video-container h3 {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        margin: 0;
        font-size: 1.2rem;
        font-weight: 600;
        text-align: center;
    }
    
    .video-wrapper {
        position: relative;
        width: 100%;
        height: 400px;
        background: #1e293b;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    #video, #response_vid {
        width: 100%;
        height: 100%;
        object-fit: cover;
        border-radius: 0 0 15px 15px;
    }
    
    #video {
        transform: scaleX(-1); /* Mirror the video for better user experience */
    }
    
    #canvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        pointer-events: none;
    }
    
    #message {
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        background: rgba(239, 68, 68, 0.9);
        color: white;
        padding: 1rem 2rem;
        border-radius: 10px;
        font-weight: 600;
        font-size: 1.1rem;
        text-align: center;
        box-shadow: 0 8px 25px rgba(239, 68, 68, 0.3);
        display: none;
        z-index: 10;
    }
    
    .status-section {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        border-radius: 15px;
        padding: 2rem;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .status-indicator {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.75rem 1.5rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 1.1rem;
        margin-bottom: 1rem;
    }
    
    .status-reading {
        background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%);
        color: white;
    }
    
    .status-recording {
        background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        color: white;
        animation: pulse 1.5s infinite;
    }
    
    .status-loading {
        background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
        color: white;
    }
    
    .status-success {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
    }
    
    .status-error {
        background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        color: white;
    }
    
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.05); }
    }
    
    .response-section {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        padding: 2rem;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .response-title {
        font-size: 1.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
    }
    
    .response-text {
        font-size: 1.3rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.2);
        padding: 1rem 2rem;
        border-radius: 10px;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.3);
        min-height: 60px;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    .predictions-section {
        background: white;
        border-radius: 15px;
        padding: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
    }
    
    .predictions-title {
        font-size: 1.5rem;
        font-weight: 700;
        color: #1e293b;
        margin-bottom: 1.5rem;
        text-align: center;
    }
    
    .predictions-list {
        max-height: 300px;
        overflow-y: auto;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 1rem;
    }
    
    .prediction-item {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        padding: 1rem;
        margin-bottom: 0.5rem;
        border-radius: 8px;
        border-left: 4px solid #10b981;
        font-weight: 500;
        color: #1e293b;
        transition: all 0.3s ease;
    }
    
    .prediction-item:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 15px rgba(16, 185, 129, 0.2);
    }
    
    .prediction-item:last-child {
        margin-bottom: 0;
    }
    
    .controls-section {
        background: #1e293b;
        color: white;
        border-radius: 15px;
        padding: 2rem;
        text-align: center;
        margin-top: 2rem;
    }
    
    .controls-title {
        font-size: 1.3rem;
        font-weight: 600;
        margin-bottom: 1rem;
    }
    
    .control-buttons {
        display: flex;
        gap: 1rem;
        justify-content: center;
        flex-wrap: wrap;
    }
    
    .control-btn {
        padding: 0.75rem 1.5rem;
        border: none;
        border-radius: 50px;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .control-btn-primary {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
    }
    
    .control-btn-secondary {
        background: linear-gradient(135deg, #64748b 0%, #475569 100%);
        color: white;
    }
    
    .control-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.2);
    }
    
    .instructions {
        background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
        border: 2px solid #f59e0b;
        border-radius: 15px;
        padding: 1.5rem;
        margin-bottom: 2rem;
    }
    
    .instructions-title {
        color: #92400e;
        font-weight: 700;
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .instructions-list {
        color: #92400e;
        margin: 0;
        padding-left: 1.5rem;
    }
    
    .instructions-list li {
        margin-bottom: 0.5rem;
        font-weight: 500;
    }
    
    @media (max-width: 768px) {
        .stream-title {
            font-size: 2rem;
        }
        
        .video-section {
            grid-template-columns: 1fr;
            gap: 1rem;
        }
        
        .video-wrapper {
            height: 250px;
        }
        
        .control-buttons {
            flex-direction: column;
            align-items: center;
        }
        
        .control-btn {
            width: 100%;
            max-width: 300px;
        }
    }
    
    @media (max-width: 480px) {
        .stream-hero {
            padding: 80px 0 40px;
        }
        
        .stream-container {
            padding: 1rem;
            margin: 1rem 0;
        }
        
        .video-wrapper {
            height: 200px;
        }
        
        .response-text {
            font-size: 1.1rem;
            padding: 0.75rem 1rem;
        }
    }
</style>
{% endblock %}

{% block scripts %}
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>
<script src="https://cdn.jsdelivr.net/npm/recordrtc@5.6.1"></script>
{% endblock scripts %}

{% block body %}
<!-- Stream Hero Section -->
<section class="stream-hero">
    <div class="container">
        <div class="stream-hero-content">
            <h1 class="stream-title">
                <i class="fas fa-video me-3"></i>
                Live Gesture Recognition
            </h1>
            <p class="stream-subtitle">
                Real-time hand gesture detection and translation for seamless communication
            </p>
        </div>
    </div>
</section>

<!-- Main Stream Container -->
<div class="container">
    <div class="stream-container">
        <!-- Instructions -->
        <div class="instructions">
            <h3 class="instructions-title">
                <i class="fas fa-info-circle"></i>
                How to Use
            </h3>
            <ol class="instructions-list">
                <li>Allow camera access when prompted</li>
                <li>Position your hand clearly in front of the camera</li>
                <li>The system will automatically detect and record your gestures</li>
                <li>View the recognized text and response video below</li>
            </ol>
        </div>

        <!-- Video Section -->
        <div class="video-section">
            <div class="video-container">
                <h3><i class="fas fa-camera me-2"></i>Live Camera Feed</h3>
                <div class="video-wrapper">
                    <video id="video" autoplay muted></video>
                    <canvas id="canvas"></canvas>
                    <div id="message">Please put your hand in front of the camera</div>
                </div>
            </div>
            
            <div class="video-container">
                <h3><i class="fas fa-play-circle me-2"></i>Response Video</h3>
                <div class="video-wrapper">
                    <video src="{{ video }}" id="response_vid" controls></video>
                </div>
            </div>
        </div>

        <!-- Status Section -->
        <div class="status-section">
            <div class="status-indicator" id="status_indicator">
                <i class="fas fa-circle-notch fa-spin"></i>
                <span id="status_text">Initializing...</span>
            </div>
            <p class="mb-0 text-muted">System Status: <span id="status_description">Preparing camera and AI models</span></p>
            
            <!-- Debug Information -->
            <div class="mt-3" style="background: #f8f9fa; padding: 1rem; border-radius: 8px; font-size: 0.9rem;">
                <strong>Debug Info:</strong>
                <div id="debug_info">
                    <div>Video Dimensions: <span id="video_dims">Not loaded</span></div>
                    <div>Canvas Dimensions: <span id="canvas_dims">Not set</span></div>
                    <div>Hand Model: <span id="model_status">Not loaded</span></div>
                    <div>Recording Status: <span id="recording_status">Not recording</span></div>
                </div>
            </div>
        </div>

        <!-- Response Section -->
        <div class="response-section">
            <h3 class="response-title">
                <i class="fas fa-comments me-2"></i>
                Recognized Text
            </h3>
            <div class="response-text" id="response_text">
                {{ translated_texts|default:"Waiting for gesture recognition..." }}
            </div>
        </div>

        <!-- Predictions Section -->
        <div class="predictions-section">
            <h3 class="predictions-title">
                <i class="fas fa-list me-2"></i>
                Recognition History
            </h3>
            <div class="predictions-list" id="predictions_list">
                {% for text in texts %}
                    <div class="prediction-item">{{ text }}</div>
                {% empty %}
                    <div class="prediction-item">No gestures recognized yet. Start by showing your hand to the camera.</div>
                {% endfor %}
            </div>
        </div>

        <!-- Controls Section -->
        <div class="controls-section">
            <h3 class="controls-title">
                <i class="fas fa-cog me-2"></i>
                System Controls
            </h3>
            <div class="control-buttons">
                <button class="control-btn control-btn-primary" onclick="restartDetection()">
                    <i class="fas fa-redo"></i>
                    Restart Detection
                </button>
                <button class="control-btn control-btn-secondary" onclick="clearHistory()">
                    <i class="fas fa-trash"></i>
                    Clear History
                </button>
                <button class="control-btn control-btn-secondary" onclick="testGestureRecognition()">
                    <i class="fas fa-video"></i>
                    Test Recognition
                </button>
            </div>
        </div>
    </div>
</div>

<script>
    // Global variables
    const videoElement = document.getElementById('video');
    const statusIndicator = document.getElementById('status_indicator');
    const statusText = document.getElementById('status_text');
    const statusDescription = document.getElementById('status_description');
    const responseText = document.getElementById('response_text');
    const predictionsList = document.getElementById('predictions_list');
    const message = document.getElementById('message');
    
    let startTime = 0;
    let recording = false;
    let recorder;
    let handModel;

    // Status management
    function updateStatus(status, text, description) {
        statusIndicator.className = `status-indicator status-${status}`;
        statusText.textContent = text;
        statusDescription.textContent = description;
    }

    // Debug information updates
    function updateDebugInfo() {
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        
        document.getElementById('video_dims').textContent = 
            video.videoWidth > 0 ? `${video.videoWidth}x${video.videoHeight}` : 'Not loaded';
        document.getElementById('canvas_dims').textContent = 
            canvas.width > 0 ? `${canvas.width}x${canvas.height}` : 'Not set';
        document.getElementById('model_status').textContent = 
            handModel ? 'Loaded' : 'Not loaded';
        document.getElementById('recording_status').textContent = 
            recording ? 'Recording' : 'Not recording';
    }

    // Cookie helper function
    function getCookie(name) {
        let cookieValue = null;
        if (document.cookie && document.cookie !== '') {
            const cookies = document.cookie.split(';');
            for (let i = 0; i < cookies.length; i++) {
                const cookie = cookies[i].trim();
                if (cookie.startsWith(name + '=')) {
                    cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                    break;
                }
            }
        }
        return cookieValue;
    }

    // Start video stream
    async function startVideo() {
        try {
            updateStatus('loading', 'Initializing...', 'Requesting camera access');
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { 
                    width: { ideal: 640, min: 320 },
                    height: { ideal: 480, min: 240 },
                    facingMode: 'user'
                } 
            });
            
            videoElement.srcObject = stream;
            
            // Wait for video to be ready
            await new Promise((resolve) => {
                videoElement.onloadedmetadata = () => {
                    videoElement.play();
                    resolve();
                };
            });
            
            // Ensure video has proper dimensions
            await new Promise((resolve) => {
                const checkDimensions = () => {
                    if (videoElement.videoWidth > 0 && videoElement.videoHeight > 0) {
                        console.log(`Video dimensions: ${videoElement.videoWidth}x${videoElement.videoHeight}`);
                        resolve();
                    } else {
                        setTimeout(checkDimensions, 100);
                    }
                };
                checkDimensions();
            });
            
            console.log('Video stream started successfully');
            updateStatus('reading', 'Ready', 'Camera active, waiting for hand gestures');
            updateDebugInfo();
        } catch (error) {
            console.error('Error accessing webcam:', error);
            updateStatus('error', 'Camera Error', 'Unable to access camera. Please check permissions.');
        }
    }

    // Start recording function
    function startRecording(stream) {
        // Try different MIME types for better compatibility
        let mimeType = 'video/webm;codecs=vp9';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'video/webm;codecs=vp8';
        }
        if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'video/webm';
        }
        if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'video/mp4';
        }
        
        console.log(`Using MIME type: ${mimeType}`);
        
        recorder = new RecordRTC(stream, {
            type: 'video',
            mimeType: mimeType,
            videoBitsPerSecond: 1000000, // 1 Mbps
            audioBitsPerSecond: 128000   // 128 kbps
        });
        
        recorder.startRecording();
        recording = true;
        startTime = Date.now();
        console.log('Recording started with MIME type:', mimeType);
        updateStatus('recording', 'Recording...', 'Capturing hand gesture (6 seconds)');
        updateDebugInfo();
        
        const recordingLength = 6000;
        setTimeout(() => {
            recorder.stopRecording(() => {
                const blob = recorder.getBlob();
                console.log(`Recording completed. Blob size: ${blob.size} bytes, type: ${blob.type}`);
                
                // Determine file extension based on MIME type
                let fileExtension = 'webm';
                if (mimeType.includes('mp4')) {
                    fileExtension = 'mp4';
                }
                
                const formData = new FormData();
                formData.append('video', blob, `hand-detection-video.${fileExtension}`);
                
                // Debug FormData contents
                console.log('FormData contents:');
                for (let [key, value] of formData.entries()) {
                    console.log(`  ${key}:`, value);
                }
                
                updateStatus('loading', 'Processing...', 'Analyzing gesture with AI model');
        
                fetch('{% url "video_app:stream_upload" %}', {
                    method: 'POST',
                    body: formData,
                    headers: {
                        'X-CSRFToken': getCookie('csrftoken')
                    }
                })
                .then(response => {
                    console.log('Response status:', response.status);
                    console.log('Response headers:', response.headers);
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    return response.json();
                })
                .then(data => {
                    console.log('Response data:', data);
                    if (data.statue === true) {
                        // Add new prediction to the list
                        const predictionItem = document.createElement('div');
                        predictionItem.className = 'prediction-item';
                        predictionItem.textContent = data.text;
                        predictionsList.insertBefore(predictionItem, predictionsList.firstChild);
                        
                        // Update response text
                        responseText.textContent = data.text;
                        
                        updateStatus('success', 'Success!', 'Gesture recognized successfully');
                        
                        // Auto-scroll to show new prediction
                        predictionItem.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                    } else {
                        updateStatus('error', 'Not Recognized', 'Gesture not recognized. Please try again.');
                    }
                    
                    setTimeout(() => {
                        recording = false;
                        updateStatus('reading', 'Ready', 'Camera active, waiting for hand gestures');
                        updateDebugInfo();
                    }, 3000);
                })
                .catch(error => {
                    console.error('Error:', error);
                    updateStatus('error', 'Upload Error', 'Failed to process gesture. Please try again.');
                    setTimeout(() => {
                        recording = false;
                        updateStatus('reading', 'Ready', 'Camera active, waiting for hand gestures');
                        updateDebugInfo();
                    }, 3000);
                });
            });
        }, recordingLength);
    }

    // Hand detection function
    async function runHandDetection() {
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');

        try {
            // Wait for video to be ready with proper dimensions
            await new Promise((resolve) => {
                const checkVideoReady = () => {
                    if (video.videoWidth > 0 && video.videoHeight > 0) {
                        // Set canvas dimensions to match video
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        console.log(`Canvas dimensions set to: ${canvas.width}x${canvas.height}`);
                        resolve();
                    } else {
                        setTimeout(checkVideoReady, 100);
                    }
                };
                checkVideoReady();
            });

            // Load the MediaPipe Hands model
            handModel = await handPoseDetection.createDetector(
                handPoseDetection.SupportedModels.MediaPipeHands, {
                runtime: 'tfjs',
                modelType: 'full'
            });
            console.log('MediaPipe Hands model loaded successfully');
            updateStatus('reading', 'Ready', 'AI model loaded, waiting for hand gestures');
            updateDebugInfo();

            // Continuously detect hands
            async function detectHands() {
                try {
                    // Check if video is ready and has valid dimensions
                    if (video.videoWidth === 0 || video.videoHeight === 0) {
                        requestAnimationFrame(detectHands);
                        return;
                    }

                    const predictions = await handModel.estimateHands(video, {
                        flipHorizontal: true // This handles the mirroring for us
                    });

                    context.clearRect(0, 0, canvas.width, canvas.height);
                    
                    if (predictions.length > 0) {
                        message.style.display = 'none';
                        
                        if (!recording) {
                            const stream = videoElement.srcObject;
                            startRecording(stream);
                        }
                        
                        // Draw hand landmarks
                        predictions.forEach(prediction => {
                            const landmarks = prediction.keypoints;
                            landmarks.forEach(landmark => {
                                const { x, y } = landmark;
                                context.beginPath();
                                context.arc(x, y, 4, 0, 2 * Math.PI);
                                context.fillStyle = '#10b981';
                                context.fill();
                                
                                // Add glow effect
                                context.shadowColor = '#10b981';
                                context.shadowBlur = 10;
                                context.beginPath();
                                context.arc(x, y, 2, 0, 2 * Math.PI);
                                context.fillStyle = '#ffffff';
                                context.fill();
                                context.shadowBlur = 0;
                            });
                        });
                    } else {
                        if (!recording) {
                            message.style.display = 'block';
                        }
                    }
                } catch (detectionError) {
                    console.error('Error during hand detection:', detectionError);
                    // Continue detection even if there's an error
                }

                requestAnimationFrame(detectHands);
            }

            detectHands();
        } catch (error) {
            console.error('Error loading hand detection model:', error);
            updateStatus('error', 'Model Error', 'Failed to load AI model. Please refresh the page.');
        }
    }

    // Control functions
    function restartDetection() {
        if (recording) {
            updateStatus('loading', 'Restarting...', 'Stopping current recording');
            setTimeout(() => {
                recording = false;
                updateStatus('reading', 'Ready', 'Camera active, waiting for hand gestures');
            }, 1000);
        } else {
            updateStatus('reading', 'Ready', 'Camera active, waiting for hand gestures');
        }
    }

    function clearHistory() {
        predictionsList.innerHTML = '<div class="prediction-item">History cleared. Start by showing your hand to the camera.</div>';
        responseText.textContent = 'Waiting for gesture recognition...';
    }

    // Test function to manually trigger gesture recognition
    function testGestureRecognition() {
        if (!videoElement.srcObject) {
            updateStatus('error', 'No Camera', 'Please start the camera first');
            return;
        }
        
        if (recording) {
            updateStatus('error', 'Already Recording', 'Please wait for current recording to finish');
            return;
        }
        
        console.log('Manual test: Starting gesture recognition');
        const stream = videoElement.srcObject;
        startRecording(stream);
    }

    // Initialize everything when page loads
    window.onload = async () => {
        try {
            await startVideo();
            // Wait a bit for video to be fully ready
            setTimeout(async () => {
                await runHandDetection();
            }, 1000);
        } catch (error) {
            console.error('Initialization error:', error);
            updateStatus('error', 'Initialization Error', 'Failed to initialize the application. Please refresh the page.');
        }
    };

    // Handle page visibility changes
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            console.log('Page hidden, pausing detection');
        } else {
            console.log('Page visible, resuming detection');
        }
    });

    // Add keyboard shortcuts
    document.addEventListener('keydown', function(event) {
        if (event.key === 'r' || event.key === 'R') {
            restartDetection();
        } else if (event.key === 'c' || event.key === 'C') {
            clearHistory();
        }
    });
</script>
{% endblock body %}
